<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Choosing and Characterizing metrics | Nothing</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="Course note of A/B testing on Udacity: Lesson 3
 Choosing and Characterizing metrics   Two types of metrics and their use cases:
 invariant checking/sanity checking metrics: metrics should not change across the experiment and the control. For example, the number of users in two groups in experiment and do they have the same distribution, like country, age, etc. For sanity checking may use multiple metrics evaludation metrics: high-level business metrics&#43;detail metrics.">
    <meta name="generator" content="Hugo 0.92.2" />
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    
    
    
      

    

    
    
    <meta property="og:title" content="Choosing and Characterizing metrics" />
<meta property="og:description" content="Course note of A/B testing on Udacity: Lesson 3
 Choosing and Characterizing metrics   Two types of metrics and their use cases:
 invariant checking/sanity checking metrics: metrics should not change across the experiment and the control. For example, the number of users in two groups in experiment and do they have the same distribution, like country, age, etc. For sanity checking may use multiple metrics evaludation metrics: high-level business metrics&#43;detail metrics." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://example.org/posts/choosing-and-characterizing-metrics/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-03-22T14:48:02+00:00" />
<meta property="article:modified_time" content="2020-03-22T14:48:02+00:00" />

<meta itemprop="name" content="Choosing and Characterizing metrics">
<meta itemprop="description" content="Course note of A/B testing on Udacity: Lesson 3
 Choosing and Characterizing metrics   Two types of metrics and their use cases:
 invariant checking/sanity checking metrics: metrics should not change across the experiment and the control. For example, the number of users in two groups in experiment and do they have the same distribution, like country, age, etc. For sanity checking may use multiple metrics evaludation metrics: high-level business metrics&#43;detail metrics."><meta itemprop="datePublished" content="2020-03-22T14:48:02+00:00" />
<meta itemprop="dateModified" content="2020-03-22T14:48:02+00:00" />
<meta itemprop="wordCount" content="1663">
<meta itemprop="keywords" content="course notes,data analytics,A/B testing," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Choosing and Characterizing metrics"/>
<meta name="twitter:description" content="Course note of A/B testing on Udacity: Lesson 3
 Choosing and Characterizing metrics   Two types of metrics and their use cases:
 invariant checking/sanity checking metrics: metrics should not change across the experiment and the control. For example, the number of users in two groups in experiment and do they have the same distribution, like country, age, etc. For sanity checking may use multiple metrics evaludation metrics: high-level business metrics&#43;detail metrics."/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Nothing
      
    </a>
    <div class="flex-l items-center">
      

      
      
<div class="ananke-socials">
  
</div>
    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        POSTS
      </aside>
      










  <div id="sharing" class="mt3 ananke-socials">
    
  </div>


      <h1 class="f1 athelas mt3 mb1">Choosing and Characterizing metrics</h1>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2020-03-22T14:48:02Z">March 22, 2020</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p><em>Course note of <a href="https://www.udacity.com/course/ab-testing--ud257">A/B testing on Udacity</a>: Lesson 3</em></p>
<!-- raw HTML omitted -->
<hr>
<h1 id="choosing-and-characterizing-metrics">Choosing and Characterizing metrics</h1>
<ul>
<li>
<p>Two types of metrics and their use cases:</p>
<ul>
<li>invariant checking/sanity checking metrics: metrics should not change across the experiment and the control. For example, the number of users in two groups in experiment and do they have the same distribution, like country, age, etc. For sanity checking may use multiple metrics</li>
<li>evaludation metrics: high-level business metrics+detail metrics. For evaluation metrics #metrics depends company. For multiple metrics, can create a composed metric - an objective function, or OEC (overall evaluation criteria) to combine metrics.</li>
</ul>
</li>
<li>
<p>Steps:</p>
<ol>
<li>
<p>High-level business metrics:</p>
<p>metrics that everyone will understand, such as active users, click-through-probability</p>
</li>
<li>
<p>Figure out details:</p>
<p>how do you define &ldquo;active&rdquo;?</p>
</li>
<li>
<p>summarize them into a single metric:</p>
<p>like sum, median, etc</p>
</li>
</ol>
</li>
</ul>
<h2 id="define">Define</h2>
<p><strong>Brainstorm and establish metrics, from high-level to practical.</strong></p>
<h3 id="refining-the-customer-funnel">Refining the customer funnel</h3>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1ga9ea9zqr1j31f40rndyz.jpg" alt=""></p>
<p>**Search &ldquo;Adacity&rdquo; may not be a good answer since not search is just one type of acquisition; **</p>
<p><strong>key idea: 1. break apart the original stage &amp; insert before or after original stages 2. follow the business objective.</strong> Since there is helping students get jobs in business objective, it is important to add get jobs in the final stage of tunnel.</p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1ga9dwkoebbj31c00u0u0x.jpg" alt=""></p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1ga9ehq61njj31c00u01ky.jpg" alt=""></p>
<p>Users may not use coaching; Users may also switch between homepage and course list. But it is still a funnel.</p>
<p>Each stage is a metric. Use more rates or probabilty than count since they are better at evaluation, such as the users switching between homepage and course list. It is better to use the convertion rate from homepage visits to course list visits.</p>
<h3 id="choose-metrics">Choose metrics</h3>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1ga9dwiwbfnj31c00u0b2a.jpg" alt=""></p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1ga9dwy66lzj31c00u0npe.jpg" alt=""></p>
<p>我的答案是3； 1，2； 5</p>
<ul>
<li>Update a description on the course list page: aimed at increase the conversion rate from course list to specific course; can also use <strong>continued progression down funnel</strong> as supplement, that is CTR to the course list page, or a drop-off rate of courses (may increase if descriptions are misleding).</li>
<li>Increase size of &ldquo;start now&rdquo; button: can also use probability. But it is better to use rates since <strong>Rates are usually better for measuring the usability of a button</strong>. (If it is hard to find or hard to click, users may click multiple times, and CTR will decrease?)</li>
<li>Explain benefits of paid service: can also use user retention (How long do users continue paying for coach) or usage metrics (among the users using coaching, do they use more).</li>
</ul>
<p>###Difficult metrics</p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1ga9dwpbpndj31c00u0x6p.jpg" alt=""></p>
<p>我的答案：2，3.</p>
<p>Rate of returning for 2nd course is also difficult because it will take too long to meature the metric (it will take a long time for users to return for 2nd course).</p>
<p>Note that difficult metrics are metrics **take too long **and <strong>do not have data</strong>.</p>
<h4 id="techniques-for-solving-difficult-metrics">Techniques for solving difficult metrics</h4>
<ol>
<li>
<p>external data</p>
<p>(1) companys that collect data, like NIelsen;</p>
<p>(2) companys run surveys of users;</p>
<p>(3) academic research, like eye tracking.</p>
<p>Use for</p>
<p>(1)brainstorming (think of new metrics),</p>
<p>(2) validation metrics, develop validation techiniques.</p>
</li>
<li>
<p>use our own data:</p>
<p>(1) use all our existing data:</p>
<ul>
<li>
<p>retrospective analysis/observational analysis, can combined with surveys&amp;focus groups&amp;etc, shows correlation not causation ;</p>
</li>
<li>
<p>running experiement: run an experiment to validate whether or not we can use a metrics for evaluating experiements, measure that metric is actually going to move as we make changes: for example, use time that student takes to complete the quiz as metrics to measure students' undertanding of the material, we need to try <em>different quizs/on different formulation</em>, and test which one move the proposed metric</p>
</li>
</ul>
<p>(2) gather new data: user experience research, survey, focus groups, etc</p>
<p>more robust to combine these methods.</p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gaboqpzo1uj31c00u0x6p.jpg" alt=""></p>
<p><strong>Pdf on website</strong></p>
<p>UER: can use special equipment, like eye tracking; need to validate results, such as retrospective analysis to see how  it varies over time or experiments to see how it varies when make changes</p>
<p>Surveys: users do not need to tell truth</p>
</li>
</ol>
<ul>
<li>
<p><strong>Example of applying other techniques</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gabor8bqbjj31c00u04qq.jpg" alt=""></p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gaborn2c77j31c00u0kjl.jpg" alt=""></p>
<ul>
<li>Rate of returning for 2nd course: if can find some metrics predictable, can use it as proxy in experiments, like the proxies in 3rd metrics.</li>
<li>Probability of finding information via search: Can use proxies, and validate them with External data; Human evaludation is pay human raters to evaluate the site.</li>
</ul>
</li>
<li>
<p>Quiz</p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gabos5rmhij31ga0u0b29.jpg" alt=""></p>
<p>我的答案：4， 6； 1，6 ；2， 5</p>
<ul>
<li>
<p>measure user engagement: use UER and observed how engaged users are; retrospective analysis of users who have completed the courses and see what they have in common.</p>
</li>
<li>
<p>Decide whether to excend inventory in shopping site: add new proeducts will be an expensive investment; user focus groups to get ideas from users about what they want</p>
</li>
<li>
<p>which ads get most views: do retrospective analysis: assume that click is correlated with view, or see the lowest position where anyone has clicked and assume that they have viewed all before</p>
</li>
</ul>
</li>
</ul>
<h2 id="build-intuition">Build Intuition</h2>
<p><strong>Build intuition and understand sensitivity and robustness.</strong></p>
<p>Turning a high-level metric into a well-defined metric:</p>
<ul>
<li>
<p>fully define exactly what data are going to look at to define the metrics: numerator/denominator/filter/ways to compute a metric</p>
<p>Many nuances, for example, in CTR, use cookie or just click?  a user view in 11:55pm and click on 12:01am, is he/she users in first day or last day? Or a user view the page but click 2 hours later, do we count it as once?</p>
<p>Consider the technology, JS ping back is different in IE and Safiri, so also need to work with engineering team to <strong>understand nuances and get accurate data</strong>.</p>
</li>
<li>
<p>summarize metric</p>
</li>
</ul>
<h3 id="example-of-define-a-metric">Example of Define a metric</h3>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gaboswrajyj31c00u0kjl.jpg" alt=""></p>
<p>When using different time interval, get different value.</p>
<p>In this example, user click, then reload  but do not click (5 minutes later). After 30 seconds, click. After 12 hours, reload but not click.</p>
<p>If per minute, orange rectangles show the groups; first and second groups have click, last one does not.</p>
<p>If per hour, purple lines show the groups; first has click, last one does not.</p>
<p>If per day, all events belongs to one group. CTR = 1</p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gaboub05kxj31c00u0npd.jpg" alt=""></p>
<p>Definition2 (use page views instead of cookie) is easier to implement than definition1. To implement definition2, give each pageview a unique id. If user refresh page, it will generate a new page view but the cookie will remains same. So the CTR will be different.</p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gabovjy851j31c00u0b29.jpg" alt=""></p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gabowl9f50j31kc0tex1r.jpg" alt=""></p>
<p>Double click: cookie and page view prob will count as single click.</p>
<p>Back button caches page: It will generate a new page view. cookie prob will count 1 page view while the other two will count 2 page views.</p>
<p>Click-tracking bug: If two clicks are recorded instead of one, similar with double-click. If click is missing, all will be influenced.</p>
<h3 id="filtering-and-segmenting">Filtering and Segmenting</h3>
<ul>
<li>
<p>Filter: filter the traffic, aimed at <strong>de-bias data or dull-bias data</strong></p>
<p>external reasons: spam, fraud, etc;</p>
<p>internal reasons: test what if if only change on subset of traffic and increase the power and sensitivity of experiment. For example, only test on English traffic.</p>
<p><strong>Do not introduce bias when filtering</strong>. For example, filter long session which may because of the website, or filter on user id where there are users without accounts. To test whether it introduce bias, slice the data (by country, etc) and complete metrics on all of these slices,  or look at week over week or day over day data. <strong>Most important: Build intuition and know what changes are expected and what are not.</strong></p>
</li>
</ul>
<h4 id="examples">Examples:</h4>
<ul>
<li>
<p>week over week/ year over year</p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gabp02j4q3j31fx0u0kjl.jpg" alt=""></p>
<p>week over week: # in Mon of this week/# in Mon of last week (here the spike shows that it is not due to week variation)</p>
<p>year over year: # in day of this year/# in day of last year (the weekday may not correspond in two years, so if there is weekend effect, it will not be smooth)</p>
</li>
<li>
<p>slice data:</p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gabp0bik0fj31c00u0x6p.jpg" alt=""></p>
</li>
<li>
<p>Quiz:<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gabp0z8ymwj31c00u0hdu.jpg" alt=""></p>
<p>By platform: mobile or web</p>
<p>我的答案：3，4，6</p>
<p>CTR and CTP over time cannot tell whether there is a problem alone.</p>
<p>Both rate and probability on same graph: In general, rates are higher than probability. <strong>So it is expected that rates are higher than probabilities. And it is hard to know how much higher would the rates be.</strong></p>
<p>CTR by platforms: Users' behavior may be different on different platform.  It is hard to tell whether it is because of JS bug or just user behavior.</p>
</li>
</ul>
<h3 id="summary-metrics">Summary Metrics</h3>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gatu29qpsaj31c00u01ky.jpg" alt=""></p>
<h4 id="sensititvity-and-robustness">sensititvity and robustness</h4>
<ul>
<li>
<p>Mean: sensitive; median: robust</p>
</li>
<li>
<p>how to measure sensitivity and robustness?</p>
<ol>
<li>
<p>running experiements or using experiments already have: whether the metrics respond to the changes</p>
<p>use a vs. a experiment to determine whether metrics are too sensitive: do not change anything</p>
</li>
<li>
<p>retrospective analysis</p>
</li>
</ol>
</li>
<li>
<p>Example of retrospective analysis:</p>
<p>plot histogram: (<strong>The distributions are similar so these videos are comparable</strong>)</p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gavwn64wepj31jx0u07wh.jpg" alt=""></p>
<p>compare different metrics: (<strong>Must make sure these 5 videos are comparable</strong>)</p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gavwnehnqwj31mv0u04qp.jpg" alt=""></p>
<p>90th and 99th percentile changes among different videos</p>
</li>
<li>
<p>Example of experiment:</p>
<p>Histogram:</p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gavwnu915vj31k10u07wh.jpg" alt=""></p>
<p>Video 1 have the highest resolution and highest load time.</p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gbgr5as2nqj31lx0u07wh.jpg" alt=""></p>
<p>Median and 80th percentile do not change among different videos.</p>
</li>
</ul>
<h2 id="characterize">Characterize</h2>
<p><strong>How to characterize the varaibility of the metrics.</strong></p>
<h3 id="variability">variability</h3>
<ul>
<li>Absolute difference vs. relative difference</li>
</ul>
<h4 id="calculating-variability">calculating variability</h4>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gatwcprdj5j31c00u0hdt.jpg" alt=""></p>
<ul>
<li>
<p>Quiz: calculating variablity analytically (with distribution)</p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gavwtq7povj31fp0sah7c.jpg" alt=""></p>
</li>
<li>
<p>calculating  variability empirically:</p>
<ul>
<li>
<p>calculate with non-parametric: <a href="%5Bhttps://baike.baidu.com/item/%E7%AC%A6%E5%8F%B7%E6%A3%80%E9%AA%8C%5D(https://baike.baidu.com/item/%E7%AC%A6%E5%8F%B7%E6%A3%80%E9%AA%8C)">sign test</a></p>
</li>
<li>
<p>A vs A experiment: run many a/a experiment with large enough samples, or run a big a/a experiment and <strong>bootstrap</strong></p>
<p>in reality: analytical (with simple metrics) → bootstrap (when metrics become complicated) → are they consistent? (if not, many a/a experiments)</p>
</li>
</ul>
</li>
<li>
<p>Examples:</p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gavyfmn48vj31wc0rv7wh.jpg" alt=""></p>
<ol>
<li>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gaw4f70l4jj31dw0qttes.jpg" alt=""></p>
<p>May plot the results of different experiments and  compare them with assumption distribution.</p>
</li>
<li>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gaw4ax5rkqj31qo0u0b29.jpg" alt=""></p>
<p>need to make an assumption of metrics, for example, metrics are normally distribution</p>
<p>how to calculate SD (calculate the SD of difference between groups):<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gaw4e6nj0hj31920u0e81.jpg" alt=""></p>
</li>
<li>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gaw4jqxlgbj31c00u0npd.jpg" alt=""></p>
<p>discard 2.5% of values of each side, then the range of the remaining data will give 95% confidence interval.</p>
<p>lower bound and higher bound of the range is just the confidence interval, <strong>do not need to add average</strong>.</p>
</li>
</ol>
</li>
<li>
<p>Quiz:</p>
<p>Data:</p>
<p><a href="https://docs.google.com/spreadsheets/d/1IFtnCTjMw023ixJIm7QvqAQ1M5peQnchyegYs1iVfyw/edit#gid=0">https://docs.google.com/spreadsheets/d/1IFtnCTjMw023ixJIm7QvqAQ1M5peQnchyegYs1iVfyw/edit#gid=0</a></p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gaw65cngu9j31p40u04qp.jpg" alt=""></p>
</li>
</ul>
<h2 id="summary">Summary</h2>
<ul>
<li>use a lot of time validating metrics</li>
<li>define metrics; consider a lot of things</li>
<li>Sensitivity and robustness</li>
<li>Variability: always start with a basic analytical estimated variability</li>
<li>Necassary: sanity checking</li>
<li>how these metrics perform in practice: anything not taken into consideration and influence the metrics; peoples' behaviors may shift through time or after some change</li>
</ul>
<ul class="pa0">
  
   <li class="list di">
     <a href="/tags/course-notes" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">course notes</a>
   </li>
  
   <li class="list di">
     <a href="/tags/data-analytics" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">data analytics</a>
   </li>
  
   <li class="list di">
     <a href="/tags/a/b-testing" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">A/B testing</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




  <div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3">Related</p>
    <ul class="pa0 list">
	   
	     <li  class="mb2">
          <a href="/posts/policy-and-ethics-for-experiments/">Policy and Ethics for Experiments</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/posts/overview-of-ab-testing/">Overview of A/B Testing</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/posts/sentiment-analysis/">Sentiment Analysis</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/posts/recsys_intro/">RecSys Intro</a>
        </li>
	    
    </ul>
</div>

</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://example.org/" >
    &copy;  Nothing 2022 
  </a>
    <div>
<div class="ananke-socials">
  
</div></div>
  </div>
</footer>

  </body>
</html>
